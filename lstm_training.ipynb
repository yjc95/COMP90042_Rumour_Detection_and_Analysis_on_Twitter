{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fafc148",
   "metadata": {},
   "source": [
    "## LSTM trainig\n",
    "This file is to build a lstm binary model to classify the text is rumor or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee6f8c",
   "metadata": {},
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e839d",
   "metadata": {},
   "source": [
    "### get initial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ad5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, x_dev_data, x_test_data = [], [], []\n",
    "y_train_data, y_dev_data = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95587aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5b0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d84b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text)\n",
    "    text = re.sub(r'@(\\w+)?', '', text)\n",
    "    text = re.sub(r'#(\\w+)?', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    word_list = [w for w in text.split() if w not in stop_words]\n",
    "    text_clean = ''\n",
    "    for w in word_list:\n",
    "        text_clean += (w + ' ')\n",
    "    if text_clean != '':\n",
    "        return text_clean\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e264a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/tweet-train-final.txt', 'r', encoding='utf-8') as f:\n",
    "    tweet_all = f.readlines()\n",
    "    for event in tweet_all:\n",
    "        # print(type(tweets), tweets)\n",
    "        tweets = json.loads(event)\n",
    "        text_event = ''\n",
    "        for k, v in tweets.items():\n",
    "            if 'data' in v:\n",
    "                text = v['data'][0]['text']\n",
    "                text = clean_text(text)\n",
    "                text_event += text\n",
    "        # print(type(text_event))\n",
    "        x_train_data.append(text_event)    \n",
    "\n",
    "with open('./project-data/train.label.txt', 'r', encoding='utf-8') as f:\n",
    "    label_all = f.readlines()\n",
    "    # print(type(label_all[1][:-1]), label_all[1][:-1])\n",
    "    for label in label_all:\n",
    "        if label[:-1] == 'rumour':\n",
    "            y_train_data.append(1)\n",
    "        else:\n",
    "            y_train_data.append(0)\n",
    "\n",
    "with open('./project-data/tweet-dev-final.txt', 'r', encoding='utf-8') as f:\n",
    "    tweet_all = f.readlines()\n",
    "    for event in tweet_all:\n",
    "        tweets = json.loads(event)\n",
    "        text_event = ''\n",
    "        for k, v in tweets.items():\n",
    "            if 'data' in v:\n",
    "                text = v['data'][0]['text']\n",
    "                text = clean_text(text)\n",
    "                text_event += text\n",
    "        x_dev_data.append(text_event)\n",
    "        \n",
    "with open('./project-data/dev.label.txt', 'r', encoding='utf-8') as f:\n",
    "    label_all = f.readlines()\n",
    "    for label in label_all:\n",
    "        if label[:-1] == 'rumour':\n",
    "            y_dev_data.append(1)\n",
    "        else:\n",
    "            y_dev_data.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56605bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/test.data.txt', 'r', encoding='utf-8') as f:\n",
    "    id_all = f.readlines()\n",
    "    for i in range(len(id_all)):\n",
    "        ids = id_all[i][:-1].split(',')\n",
    "        text_event = ''\n",
    "        for j in range(len(ids)):\n",
    "            file_path = './project-data/tweet-objects/' + ids[j] + '.json'\n",
    "            with open(file_path, 'r', encoding='utf-8') as f2:\n",
    "                tweet = json.load(f2)\n",
    "                text_event += tweet['text']\n",
    "        x_test_data.append(text_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading given tsv file\n",
    "with open(\"./project-data/train.tsv\", 'r') as tsv_file:\n",
    "    with open(\"./project-data/train_data.csv\", 'w') as csv_file:\n",
    "        for line in tsv_file:\n",
    "            csv_file.write(line)\n",
    "df_train = pd.read_csv('./project-data/train_data.csv',delimiter=',',encoding='utf-8') \n",
    "df_dev = pd.read_csv('./project-data/dev_data.csv',delimiter=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d7f67",
   "metadata": {},
   "source": [
    "### text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29cfe844",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 512\n",
    "embedding_vecor_length = 512\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_train_data, y_train_data, test_size=0.02, random_state=4)\n",
    "\n",
    "# tokenize words\n",
    "tokenizer = Tokenizer(num_words=max_words) \n",
    "tokenizer.fit_on_texts(x_train_data) \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# X_train_sequences = tokenizer.texts_to_sequences(X_train) \n",
    "# X_test_sequences = tokenizer.texts_to_sequences(X_test) \n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(x_train_data) \n",
    "X_test_sequences = tokenizer.texts_to_sequences(x_dev_data) \n",
    "\n",
    "\n",
    "X_train = np.array(X_train_sequences)\n",
    "X_test = np.array(X_test_sequences)\n",
    "y_train = np.array(y_train_data)\n",
    "y_test = np.array(y_dev_data)\n",
    "\n",
    "X_train_pad = sequence.pad_sequences(X_train, max_len)\n",
    "X_test_pad = sequence.pad_sequences(X_test, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8095222",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ffc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,max_len,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.1)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "311cc542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 512, 512)          2560000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,724,609\n",
      "Trainable params: 2,724,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/np/6wcw_zfs1cvg8nx5694wg55m0000gn/T/ipykernel_1258/1171852026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit(X_train_pad,y_train,batch_size=128,epochs=10,\n\u001b[0;32m----> 4\u001b[0;31m           validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train_pad,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "239e0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 512, 512)          2560000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,724,609\n",
      "Trainable params: 2,724,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.7309WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 1s/step - loss: 0.6657 - accuracy: 0.7309 - val_loss: 0.5889 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.7789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5075 - accuracy: 0.7789 - val_loss: 0.4582 - val_accuracy: 0.7816\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8021WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3643 - accuracy: 0.8021 - val_loss: 0.3753 - val_accuracy: 0.8149\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9172WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2337 - accuracy: 0.9172 - val_loss: 0.3442 - val_accuracy: 0.8497\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9736WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1173 - accuracy: 0.9736 - val_loss: 0.3295 - val_accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9810WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.3411 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.3771 - val_accuracy: 0.8877\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.4297 - val_accuracy: 0.8924\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.4437 - val_accuracy: 0.8908\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.4593 - val_accuracy: 0.8829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139f589a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "# model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train_pad, y_train, epochs=10, batch_size=256,verbose = 1,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f657b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 512, 512)          2560000   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,724,609\n",
      "Trainable params: 2,724,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.7430WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 15s 883ms/step - loss: 0.6004 - accuracy: 0.7430 - val_loss: 0.5095 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8164WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 13s 890ms/step - loss: 0.3901 - accuracy: 0.8164 - val_loss: 0.3509 - val_accuracy: 0.8402\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9430WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 818ms/step - loss: 0.1684 - accuracy: 0.9430 - val_loss: 0.3212 - val_accuracy: 0.8892\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 828ms/step - loss: 0.0615 - accuracy: 0.9789 - val_loss: 0.3339 - val_accuracy: 0.8956\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9900WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 814ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.3667 - val_accuracy: 0.8908\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9926WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.4142 - val_accuracy: 0.8987\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9947WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 818ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.4442 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 815ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.4595 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.4712 - val_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.4865 - val_accuracy: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ae19880>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RNN()\n",
    "model2.summary()\n",
    "# model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['accuracy'])\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model2.fit(X_train_pad, y_train, epochs=10, batch_size=128,verbose = 1,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d40eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 512, 512)          2560000   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,724,609\n",
      "Trainable params: 2,724,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 13s - loss: 0.6647 - accuracy: 0.7530 - val_loss: 0.5905 - val_accuracy: 0.7801 - 13s/epoch - 2s/step\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 12s - loss: 0.5129 - accuracy: 0.7784 - val_loss: 0.4576 - val_accuracy: 0.7816 - 12s/epoch - 1s/step\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 12s - loss: 0.3610 - accuracy: 0.8016 - val_loss: 0.3644 - val_accuracy: 0.8180 - 12s/epoch - 2s/step\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 12s - loss: 0.2218 - accuracy: 0.9272 - val_loss: 0.3440 - val_accuracy: 0.8782 - 12s/epoch - 1s/step\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 13s - loss: 0.1138 - accuracy: 0.9720 - val_loss: 0.3030 - val_accuracy: 0.8734 - 13s/epoch - 2s/step\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 12s - loss: 0.0544 - accuracy: 0.9826 - val_loss: 0.3216 - val_accuracy: 0.8908 - 12s/epoch - 2s/step\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 13s - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.3517 - val_accuracy: 0.9003 - 13s/epoch - 2s/step\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 11s - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.3920 - val_accuracy: 0.9003 - 11s/epoch - 1s/step\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 11s - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.3991 - val_accuracy: 0.9051 - 11s/epoch - 1s/step\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 - 12s - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.4269 - val_accuracy: 0.9035 - 12s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b8c4f70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RNN()\n",
    "model2.summary()\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model2.fit(X_train_pad, y_train, epochs=10, batch_size=256,verbose = 2,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43a84bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_9 (Embedding)     (None, 512, 512)          2560000   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,724,609\n",
      "Trainable params: 2,724,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/10\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c4accd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RNN()\n",
    "model2.summary()\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model2.fit(X_train_pad, y_train, epochs=10, batch_size=256,verbose = 3,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c300d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.45%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_pad,y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f5fbe",
   "metadata": {},
   "source": [
    "### predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d3498d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test_clean)\n",
    "\n",
    "x_data = np.array(x_test_sequences)\n",
    "\n",
    "x_data_pad = sequence.pad_sequences(x_data, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1ae8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(x_data_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24a5c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea091edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/lstm-predict.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = ['Id', 'Predicted']\n",
    "    writer.writerow(header)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_final = 0\n",
    "        y_pred_tmp = sigmoid(y_pred[i])\n",
    "        if y_pred_tmp > 0.511:\n",
    "            y_pred_final = 1\n",
    "        data = [i, y_pred_final]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435eff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
