{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa8e185",
   "metadata": {},
   "source": [
    "## LSTM trainig\n",
    "This file is to build a lstm binary model to classify the text is rumor or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30c1ce",
   "metadata": {},
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a64de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a491d9",
   "metadata": {},
   "source": [
    "### get initial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ad5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, x_dev_data, x_test_data = [], [], []\n",
    "y_train_data, y_dev_data = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95587aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5b0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d84b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text)\n",
    "    text = re.sub(r'@(\\w+)?', '', text)\n",
    "    text = re.sub(r'#(\\w+)?', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    word_list = [w for w in text.split() if w not in stop_words]\n",
    "    text_clean = ''\n",
    "    for w in word_list:\n",
    "        text_clean += (w + ' ')\n",
    "    if text_clean != '':\n",
    "        return text_clean\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e264a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/tweet-train-final.txt', 'r', encoding='utf-8') as f:\n",
    "    tweet_all = f.readlines()\n",
    "    for event in tweet_all:\n",
    "        # print(type(tweets), tweets)\n",
    "        tweets = json.loads(event)\n",
    "        text_event = ''\n",
    "        for k, v in tweets.items():\n",
    "            if 'data' in v:\n",
    "                text = v['data'][0]['text']\n",
    "                text = clean_text(text)\n",
    "                text_event += text\n",
    "        # print(type(text_event))\n",
    "        x_train_data.append(text_event)    \n",
    "\n",
    "with open('./project-data/train.label.txt', 'r', encoding='utf-8') as f:\n",
    "    label_all = f.readlines()\n",
    "    # print(type(label_all[1][:-1]), label_all[1][:-1])\n",
    "    for label in label_all:\n",
    "        if label[:-1] == 'rumour':\n",
    "            y_train_data.append(1)\n",
    "        else:\n",
    "            y_train_data.append(0)\n",
    "\n",
    "with open('./project-data/tweet-dev-final.txt', 'r', encoding='utf-8') as f:\n",
    "    tweet_all = f.readlines()\n",
    "    for event in tweet_all:\n",
    "        tweets = json.loads(event)\n",
    "        text_event = ''\n",
    "        for k, v in tweets.items():\n",
    "            if 'data' in v:\n",
    "                text = v['data'][0]['text']\n",
    "                text = clean_text(text)\n",
    "                text_event += text\n",
    "        x_dev_data.append(text_event)\n",
    "        \n",
    "with open('./project-data/dev.label.txt', 'r', encoding='utf-8') as f:\n",
    "    label_all = f.readlines()\n",
    "    for label in label_all:\n",
    "        if label[:-1] == 'rumour':\n",
    "            y_dev_data.append(1)\n",
    "        else:\n",
    "            y_dev_data.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56605bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/test.data.txt', 'r', encoding='utf-8') as f:\n",
    "    id_all = f.readlines()\n",
    "    for i in range(len(id_all)):\n",
    "        ids = id_all[i][:-1].split(',')\n",
    "        text_event = ''\n",
    "        for j in range(len(ids)):\n",
    "            file_path = './project-data/tweet-objects/' + ids[j] + '.json'\n",
    "            with open(file_path, 'r', encoding='utf-8') as f2:\n",
    "                tweet = json.load(f2)\n",
    "                text_event += tweet['text']\n",
    "        x_test_data.append(text_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading given tsv file\n",
    "with open(\"./project-data/train.tsv\", 'r') as tsv_file:\n",
    "    with open(\"./project-data/train_data.csv\", 'w') as csv_file:\n",
    "        for line in tsv_file:\n",
    "            csv_file.write(line)\n",
    "df_train = pd.read_csv('./project-data/train_data.csv',delimiter=',',encoding='utf-8') \n",
    "df_dev = pd.read_csv('./project-data/dev_data.csv',delimiter=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14558f23",
   "metadata": {},
   "source": [
    "### text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29cfe844",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 512\n",
    "embedding_vecor_length = 512\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x_train_data, y_train_data, test_size=0.02, random_state=4)\n",
    "\n",
    "# tokenize words\n",
    "tokenizer = Tokenizer(num_words=max_words) \n",
    "tokenizer.fit_on_texts(x_train_data) \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# X_train_sequences = tokenizer.texts_to_sequences(X_train) \n",
    "# X_test_sequences = tokenizer.texts_to_sequences(X_test) \n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(x_train_data) \n",
    "X_test_sequences = tokenizer.texts_to_sequences(x_dev_data) \n",
    "\n",
    "\n",
    "X_train = np.array(X_train_sequences)\n",
    "X_test = np.array(X_test_sequences)\n",
    "y_train = np.array(y_train_data)\n",
    "y_test = np.array(y_dev_data)\n",
    "\n",
    "X_train_pad = sequence.pad_sequences(X_train, max_len)\n",
    "X_test_pad = sequence.pad_sequences(X_test, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63e8be",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ffc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,max_len,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.1)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "239e0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 512, 512)          25600000  \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,764,609\n",
      "Trainable params: 25,764,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.7061WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6716 - accuracy: 0.7061 - val_loss: 0.6074 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7794WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5193 - accuracy: 0.7794 - val_loss: 0.4889 - val_accuracy: 0.7816\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8084WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3663 - accuracy: 0.8084 - val_loss: 0.3861 - val_accuracy: 0.8149\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.9398WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2207 - accuracy: 0.9398 - val_loss: 0.3246 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0811 - accuracy: 0.9805 - val_loss: 0.3487 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9894WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.3820 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.4183 - val_accuracy: 0.8892\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9942WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4239 - val_accuracy: 0.8782\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.4250 - val_accuracy: 0.8829\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.4328 - val_accuracy: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c93f130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "# model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train_pad, y_train, epochs=10, batch_size=256,verbose = 1,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f657b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 512)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 512, 512)          25600000  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                147712    \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,764,609\n",
      "Trainable params: 25,764,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.7135WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6694 - accuracy: 0.7135 - val_loss: 0.6015 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5108 - accuracy: 0.7789 - val_loss: 0.4829 - val_accuracy: 0.7832\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8137WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3714 - accuracy: 0.8137 - val_loss: 0.3870 - val_accuracy: 0.8180\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9346WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2284 - accuracy: 0.9346 - val_loss: 0.3323 - val_accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9763WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0879 - accuracy: 0.9763 - val_loss: 0.3168 - val_accuracy: 0.8797\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.3538 - val_accuracy: 0.8877\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.3852 - val_accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9942WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.4040 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.4164 - val_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.4267 - val_accuracy: 0.8987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bd23670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "# model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train_pad, y_train, epochs=10, batch_size=256,verbose = 1,callbacks = callbacks_list,validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c300d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.45%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_pad,y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429db8a5",
   "metadata": {},
   "source": [
    "### predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d3498d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test_clean)\n",
    "\n",
    "x_data = np.array(x_test_sequences)\n",
    "\n",
    "x_data_pad = sequence.pad_sequences(x_data, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1ae8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(x_data_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24a5c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea091edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./project-data/lstm-predict.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = ['Id', 'Predicted']\n",
    "    writer.writerow(header)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_final = 0\n",
    "        y_pred_tmp = sigmoid(y_pred[i])\n",
    "        if y_pred_tmp > 0.511:\n",
    "            y_pred_final = 1\n",
    "        data = [i, y_pred_final]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435eff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
